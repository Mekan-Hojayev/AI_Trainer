{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "miCvdtWweYPI",
    "outputId": "b5162681-51e1-4b21-8ad3-a1de99a08803"
   },
   "outputs": [],
   "source": [
    "# !pip install -q mediapipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "8589vjTvmd17"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "# from google.colab.patches import cv2_imshow\n",
    "import PoseModule as pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_video(input_path, output_path, times):\n",
    "    cap = cv2.VideoCapture(input_path)\n",
    "    original_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    original_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    width = int(original_width / times)\n",
    "    height = int(original_height / times)\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_path, fourcc, 30, (width, height))\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        resized_frame = cv2.resize(frame, (width, height))\n",
    "        out.write(resized_frame)\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "\n",
    "    print(\"Video resizing complete.\")\n",
    "\n",
    "# If input video is with high resolution we need resize\n",
    "\n",
    "# input_path = \"20231220_113403_001.mp4\"\n",
    "# output_path = \"output_video.mp4\"\n",
    "# resize_video(input_path, output_path, times = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aitrainer(feedback_type: str, body: str, level: str):\n",
    "    if feedback_type == 'real_time':\n",
    "        cap = cv2.VideoCapture(0)\n",
    "        save_video = False\n",
    "    else:\n",
    "        cap = cv2.VideoCapture(feedback_type)\n",
    "        save_video = True\n",
    "    detector = pm.poseDetector()\n",
    "    count = 0\n",
    "    dir_ = 0\n",
    "    pTime = 0\n",
    "\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(f'aitrainer_mediapipe_{feedback_type}.mp4', fourcc, 30.0, (width, height))\n",
    "\n",
    "    while True:\n",
    "        success, img = cap.read()\n",
    "        if not success:\n",
    "            break\n",
    "        if feedback_type == 'real_time':\n",
    "            img = cv2.flip(img, 1)\n",
    "        img = detector.findPose(img, False)\n",
    "        lmList = detector.findPosition(img, False)\n",
    "\n",
    "        if len(lmList) != 0:\n",
    "            if body == 'right_arm':\n",
    "                angle = detector.findAngle(img, 11, 13, 15)\n",
    "            if body == 'left_arm':\n",
    "                angle = detector.findAngle(img, 12, 14, 16)\n",
    "            if body == 'right_foot':\n",
    "                angle = detector.findAngle(img, 23, 25, 27)\n",
    "            if body == 'left_foot':\n",
    "                angle = detector.findAngle(img, 24, 26, 28)\n",
    "            if body == 'abs':\n",
    "                angle = detector.findAngle(img, 25, 23, 11)\n",
    "            \n",
    "            if level == 'easy':\n",
    "                per = np.interp(angle, (80, 110), (0, 100))\n",
    "                bar = np.interp(angle, (80, 110), (300, 100))\n",
    "            if level == 'medium':\n",
    "                per = np.interp(angle, (60, 130), (0, 100))\n",
    "                bar = np.interp(angle, (60, 130), (300, 100))\n",
    "            if level == 'hard':\n",
    "                per = np.interp(angle, (45, 150), (0, 100))\n",
    "                bar = np.interp(angle, (45, 150), (300, 100))\n",
    "            \n",
    "            color = (0, 255, 255)\n",
    "            if per == 100:\n",
    "                color = (0, 255, 0)\n",
    "                if dir_ == 0:\n",
    "                    count += 0.5\n",
    "                    dir_ = 1\n",
    "            if per == 0:\n",
    "                color = (0, 0, 255)\n",
    "                if dir_ == 1:\n",
    "                    count += 0.5\n",
    "                    dir_ = 0\n",
    "\n",
    "            cv2.rectangle(img, (10, 100), (50, 300), color, 3)\n",
    "            cv2.rectangle(img, (10, int(bar)), (50, 300), color, cv2.FILLED)\n",
    "            cv2.putText(img, f'{int(per)}%', (10, 75), cv2.FONT_HERSHEY_PLAIN, 2, color, 2)\n",
    "\n",
    "            text = f'count: {int(count)}'\n",
    "            text_size, _ = cv2.getTextSize(text, cv2.FONT_HERSHEY_PLAIN, 3, 3)\n",
    "            cv2.rectangle(img, (80, 80 - text_size[1]), (text_size[0] + 90, 80), (255, 255, 255), cv2.FILLED)\n",
    "            cv2.putText(img, text, (80, 80), cv2.FONT_HERSHEY_PLAIN, 3, (255, 0, 0), 3)\n",
    "\n",
    "        cTime = time.time()\n",
    "        fps = 1 / (cTime - pTime)\n",
    "        pTime = cTime\n",
    "\n",
    "        fps_text = f'fps: {int(fps)}'\n",
    "        fps_text_size, _ = cv2.getTextSize(fps_text, cv2.FONT_HERSHEY_PLAIN, 3, 3)\n",
    "        cv2.rectangle(img, (80, 40 - fps_text_size[1]), (fps_text_size[0] + 90, 40), (255, 255, 255), cv2.FILLED)\n",
    "        cv2.putText(img, fps_text, (80, 40), cv2.FONT_HERSHEY_PLAIN, 3, (255, 0, 0), 3)\n",
    "        out.write(img)\n",
    "\n",
    "        if save_video:\n",
    "            out.write(img)\n",
    "\n",
    "        cv2.imshow(\"YourAiTrainer\", img)\n",
    "        cv2.waitKey(1)\n",
    "\n",
    "    cap.release()\n",
    "    if save_video:\n",
    "        out.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "aitrainer('output_video.mp4', 'right_foot', 'easy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mekan\\AppData\\Local\\Temp\\ipykernel_9004\\238239944.py:8: RuntimeWarning: invalid value encountered in arccos\n",
      "  angle = np.degrees(np.arccos(cosine_angle))\n",
      "C:\\Users\\Mekan\\AppData\\Local\\Temp\\ipykernel_9004\\238239944.py:7: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  cosine_angle = np.dot(BA, BC) / (np.linalg.norm(BA) * np.linalg.norm(BC))\n"
     ]
    }
   ],
   "source": [
    "def calculate_angle(A, B, C):\n",
    "    BA = A - B\n",
    "    BC = C - B\n",
    "    cosine_angle = np.dot(BA, BC) / (np.linalg.norm(BA) * np.linalg.norm(BC))\n",
    "    angle = np.degrees(np.arccos(cosine_angle))\n",
    "    return angle\n",
    "\n",
    "def find_most_active_points(points, last_points):\n",
    "    if points.shape[0] != last_points.shape[0]:\n",
    "        return points\n",
    "    else:\n",
    "        displacements = np.linalg.norm(points - last_points, axis=1)\n",
    "        active_indices = np.argsort(displacements)[-3:]\n",
    "\n",
    "        return points[active_indices]\n",
    "\n",
    "def detect_keypoints_dummy(frame):\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    orb = cv2.ORB_create()\n",
    "    keypoints = orb.detect(gray, None)\n",
    "    keypoints = np.array([kp.pt for kp in keypoints])\n",
    "    return keypoints\n",
    "\n",
    "def main():\n",
    "    cap = cv2.VideoCapture('video_2023-12-20_13-20-51.mp4')\n",
    "    ret, last_frame = cap.read()\n",
    "    last_points = detect_keypoints_dummy(last_frame)\n",
    "    fps_ = cap.get(cv2.CAP_PROP_FPS)\n",
    "    delay = int(1000 / fps_)\n",
    "    count = 0\n",
    "    pTime = 0\n",
    "\n",
    "    # Obtain frame width and height\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    # Define the codec and create a VideoWriter object\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Define the codec (codec may vary based on system configuration)\n",
    "    out = cv2.VideoWriter('output_comparison_1.mp4', fourcc, 30.0, (frame_width, frame_height))  # Create VideoWriter object\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        current_points = detect_keypoints_dummy(frame)\n",
    "        active_points = find_most_active_points(current_points, last_points)\n",
    "        last_points = current_points\n",
    "        if len(active_points) == 3:\n",
    "            active_points = np.round(active_points).astype(int)\n",
    "            angle = calculate_angle(active_points[0], active_points[1], active_points[2])\n",
    "            if abs(180 - angle) > 179.65:\n",
    "                count += 0.5\n",
    "            elif abs(180 - angle) < 0.35:\n",
    "                count += 0.5\n",
    "            cv2.putText(frame, f\"Count: {int(count)}\", (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "        \n",
    "        cTime = time.time()\n",
    "        fps = 1 / (cTime - pTime)\n",
    "        pTime = cTime\n",
    "        \n",
    "        cv2.putText(frame, f\"FPS: {round(fps, 4)}\", (10, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "        cv2.imshow(\"Frame\", frame)\n",
    "        \n",
    "        # Write the frame to the video file\n",
    "        out.write(frame)\n",
    "\n",
    "        if cv2.waitKey(delay) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Release the VideoWriter object and capture object\n",
    "    out.release()\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate and save videoes\n",
    "\n",
    "cap1 = cv2.VideoCapture('aitrainer_comparison_1.mp4')\n",
    "cap2 = cv2.VideoCapture('output_comparison_1.mp4')\n",
    "\n",
    "width1 = int(cap1.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "width2 = int(cap2.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height1 = int(cap1.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "height2 = int(cap2.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "height = max(height1, height2)\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter('abs.mp4', fourcc, 30.0, (width1 + width2 + 150, height))\n",
    "\n",
    "while True:\n",
    "    ret1, frame1 = cap1.read()\n",
    "    ret2, frame2 = cap2.read()\n",
    "\n",
    "    if not ret1 or not ret2:\n",
    "        break\n",
    "\n",
    "    frame1 = cv2.resize(frame1, (width1, height)) if ret1 else np.zeros((height, width1, 3), dtype='uint8')\n",
    "    frame2 = cv2.resize(frame2, (width2, height)) if ret2 else np.zeros((height, width2, 3), dtype='uint8')\n",
    "\n",
    "    label_space = np.zeros((height, 150, 3), dtype='uint8')\n",
    "    cv2.putText(label_space, \"<- with mediapipe\", (0, 50), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "    cv2.putText(label_space, \"my approach ->\", (10, height - 50), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "\n",
    "    combined_frame = np.concatenate((frame1, label_space, frame2), axis=1)\n",
    "    out.write(combined_frame)\n",
    "\n",
    "cap1.release()\n",
    "cap2.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tkinter as tk\n",
    "# from tkinter import filedialog\n",
    "\n",
    "# def open_file_dialog():\n",
    "#     root = tk.Tk()\n",
    "#     root.withdraw()  # Hide the root window\n",
    "\n",
    "#     file_path = filedialog.askopenfilename()  # Open a file dialog for manual file selection\n",
    "#     if file_path:\n",
    "#         print(\"Selected file:\", file_path)\n",
    "#         # Perform further operations with the selected file\n",
    "\n",
    "# video = open_file_dialog()  # Call the function to open the file dialog"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
